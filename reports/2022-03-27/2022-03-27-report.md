# Report Week 03/27/22
## Activities/Accomplishments and Concepts/Lessons Learned
* Familiarized myself with API and features of OpenAI Gym
  * learned how to run episodes on various environments with a random policy as a baseline
  * learned how to use vectorized environments to run multiple independent sub-environments sequentially or in parallel
  * learned about the different types of spaces and how to create custom spaces
  * learned about wrappers and to create ActionWrappers, ObservationWrappers, RewardWrappers, and General Wrappers to modify the action, observation, or rewards being input/output by the environment
  * learned how to create custom environments for agent learning problems

## Issues/Problems
None!

## Plans
* Now that I have an understanding of the OpenAI Gym API, I want to implement some learning algorithms such as Q-learning on various environments provided by Gym
* watch/take notes on DeepMind x UCL RL lecture series 3: MDPs and Dynamic Programming
* I'm hoping to work on implementing RL algorithms
  * thinking of doing so in raycasting environment to see if I can get different results than Prof. Clark
  * possibly also might implement a Catan RL agent
* Hoping to work on transferring RL agent to modified test environments
  * for raycasting environment this may mean different textures
    * however this would focus more on the visual input of the problem rather than the strategic aspect
  * for Catan this may mean applying the agent to the expansion pack
    * this would be especially interesting since it would help determine whether the strategies in the original Catan can be applied directly to the expansion pack or whether the agent would have to 'rethink' its strategy
